{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p style=\"float: right;\"><img width=\"66%\" src=\"templates/logo_fmriflows.gif\"></p>\n",
    "    <h1>Functional Preprocessing</h1>\n",
    "    <p>This notebooks preprocesses functional MRI images by executing the following processing steps:\n",
    "\n",
    "1. Image preparation\n",
    "    1. Reorient images to RAS\n",
    "    1. Removal of non-steady state volumes \n",
    "    1. Brain extraction with Nilearn\n",
    "1. Motion correction\n",
    "    1. Either direct motion correction with FSL\n",
    "    1. Or, if low-pass filter specified, multistep motion correction with FSL and Python\n",
    "1. Slice-wise correction with SPM\n",
    "1. Two-step coregistration using Rigid and BBR with FSL, using WM segmentation from SPM\n",
    "1. Temporal filtering with AFNI (optional)\n",
    "1. Spatial filtering (i.e. smoothing) with Nilearn\n",
    "\n",
    "Additional, this workflow also computes:\n",
    " - Friston's 24-paramter model for motion parameters\n",
    " - Framewise Displacement (FD) and DVARS\n",
    " - Average signal in total volume, in GM, in WM and in CSF\n",
    " - Anatomical CompCor components\n",
    " - Temporal CompCor components\n",
    " - Independent components in image before smoothing\n",
    " \n",
    "**Note:** This notebook requires that the anatomical preprocessing pipeline was already executed and that it's output can be found in the dataset folder under `dataset/derivatives/fmriflows/preproc_anat`. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure Requirements\n",
    "\n",
    "The data structure to run this notebook should be according to the BIDS format:\n",
    "\n",
    "    dataset\n",
    "    ├── fmriflows_spec_preproc.json\n",
    "    ├── sub-{sub_id}\n",
    "    │   └── func\n",
    "    │       └── sub-{sub_id}_task-{task_id}[_run-{run_id}]_bold.nii.gz\n",
    "    └── task-{task_id}_bold.json\n",
    "    \n",
    "**Note:** Subfolders for individual scan sessions and `run` identifiers are optional.\n",
    "\n",
    "`fmriflows` will run the preprocessing on all files of a particular subject and a particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Specifications\n",
    "\n",
    "This notebook will extract the relevant processing specifications from the `fmriflows_spec_preproc.json` file in the dataset folder. In the current setup, they are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join as opj\n",
    "\n",
    "spec_file = opj('/data', 'fmriflows_spec_preproc.json')\n",
    "\n",
    "with open(spec_file) as f:\n",
    "    specs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters for functional preprocessing workflow\n",
    "subject_list = specs['subject_list_func']\n",
    "session_list = specs['session_list_func']\n",
    "task_list = specs['task_list']\n",
    "run_list = specs['run_list']\n",
    "ref_timepoint = specs['ref_timepoint']\n",
    "res_func = specs['res_func']\n",
    "filters_spatial = specs['filters_spatial']\n",
    "filters_temporal = specs['filters_temporal']\n",
    "n_compcor_confounds = specs['n_compcor_confounds']\n",
    "outlier_thr = specs['outlier_thresholds']\n",
    "n_independent_components = specs['n_independent_components']\n",
    "n_proc = specs['n_parallel_jobs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to change any of those values manually, overwrite them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subject identifiers\n",
    "subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of session identifiers\n",
    "session_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of task identifiers\n",
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of run identifiers\n",
    "run_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference timepoint for slice time correction (in ms)\n",
    "ref_timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requested voxel resolution after coregistration of functional images\n",
    "res_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of spatial filters (smoothing) to apply (separetely, i.e. with iterables)\n",
    "# Values are given in mm\n",
    "filters_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of temporal filters to apply (separetely, i.e. with iterables)\n",
    "# Values are given in seconds\n",
    "filters_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CompCor components to compute\n",
    "n_compcor_confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for outlier detection (3.27 represents a threshold of 99.9%)\n",
    "# Values stand for FD, DVARS, TV, GM, WM, CSF\n",
    "outlier_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of independent components to compute\n",
    "n_independent_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parallel jobs to run\n",
    "n_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_norm = [2.0, 2.0, 2.0]\n",
    "norm_func = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Workflow\n",
    "\n",
    "To ensure a good overview of the functional preprocessing, the workflow was divided into three subworkflows:\n",
    "\n",
    "1. The Main Workflow, i.e. doing the actual preprocessing. Containing subworkflows for...\n",
    "    1. Image preparation\n",
    "    1. Motion correction\n",
    "    1. Image coregistration\n",
    "    1. Temporal filtering (optional)\n",
    "2. The Confound Workflow, i.e. computing confound variables\n",
    "3. Report Workflow, i.e. visualizating relevant steps for quality control\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os.path import join as opj\n",
    "from nipype import Workflow, Node, IdentityInterface, Function\n",
    "from nipype.interfaces.image import Reorient\n",
    "from nipype.interfaces.fsl import FLIRT\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.algorithms.confounds import (\n",
    "    ACompCor, TCompCor, FramewiseDisplacement, ComputeDVARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify SPM location\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('/opt/spm12-r7219/spm12_mcr/spm12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Execution Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths and names\n",
    "exp_dir = '/data/derivatives'\n",
    "out_dir = 'fmriflows'\n",
    "work_dir = '/workingdir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a subworkflow for the Main Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preparation subworkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorient anatomical images to RAS\n",
    "reorient = Node(Reorient(orientation='RAS'), name='reorient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract brain from functional image\n",
    "def extract_brain(in_file):\n",
    "\n",
    "    from nipype.interfaces.fsl import BET\n",
    "    from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "    from nilearn.image import mean_img, new_img_like, load_img\n",
    "    from scipy.ndimage import binary_dilation, binary_fill_holes\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # Compute mean image\n",
    "    img_mean = mean_img(in_file).to_filename('mean.nii.gz')\n",
    "\n",
    "    # Apply N4BiasFieldCorrection on mean file\n",
    "    res = N4BiasFieldCorrection(input_image='mean.nii.gz',\n",
    "                                dimension=3, copy_header=True).run()\n",
    "\n",
    "    # Create brain mask based on functional bias corrected mean file\n",
    "    res = BET(in_file=res.outputs.output_image, mask=True,\n",
    "              no_output=True, robust=True).run()\n",
    "    \n",
    "    # Dilate mask and fill holes\n",
    "    img_mask = load_img(res.outputs.mask_file)\n",
    "    mask = binary_fill_holes(binary_dilation(img_mask.get_data(),\n",
    "                                             iterations=2))\n",
    "    img_mask = new_img_like(in_file, mask, copy_header=True)\n",
    "\n",
    "    # Save mask image\n",
    "    mask_file = abspath(basename(in_file).replace('.nii', '_mask.nii'))\n",
    "    img_mask.to_filename(mask_file)\n",
    "    \n",
    "    return mask_file\n",
    "\n",
    "mask_func_brain = Node(Function(input_names=['in_file'],\n",
    "                                output_names=['mask_file'],\n",
    "                                function=extract_brain),\n",
    "                       name='mask_func_brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Non-Steady State volumes and save information to file\n",
    "def detect_non_stead_states(in_file):\n",
    "    \n",
    "    import numpy as np\n",
    "    from os.path import basename, abspath\n",
    "    from nipype.algorithms.confounds import NonSteadyStateDetector\n",
    "    \n",
    "    # Detect Non-Steady State volumes\n",
    "    res = NonSteadyStateDetector(in_file=in_file).run()\n",
    "    t_min = res.outputs.n_volumes_to_discard\n",
    "    \n",
    "    nss_file = abspath(basename(in_file).replace('.nii.gz', '_nss.txt'))\n",
    "    np.savetxt(nss_file, [t_min], fmt='%d')\n",
    "    \n",
    "    return t_min, nss_file\n",
    "\n",
    "nss_detection = Node(Function(input_names=['in_file'],\n",
    "                              output_names=['t_min', 'nss_file'],\n",
    "                              function=detect_non_stead_states),\n",
    "                     name='nss_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image preparation workflow\n",
    "prepareflow = Workflow(name='prepareflow')\n",
    "\n",
    "# Add nodes to workflow and connect them\n",
    "prepareflow.connect([(reorient, nss_detection, [('out_file', 'in_file')]),\n",
    "                     (reorient, mask_func_brain, [('out_file', 'in_file')]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion & Slice-time correction nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NSS volumes and estimate original motion parameters on masked brain\n",
    "def estimate_motion_parameters(in_file, mask_file, t_min):\n",
    "\n",
    "    import os\n",
    "    from nipype.interfaces.fsl import MCFLIRT\n",
    "    from nilearn.image import load_img, math_img, new_img_like\n",
    "    from os.path import basename, abspath, dirname\n",
    "\n",
    "    # Specify name of output file\n",
    "    out_file = abspath(basename(in_file).replace('.nii.gz', '_mcf.nii.gz'))\n",
    "\n",
    "    # Remove NSS volumes from functional image\n",
    "    img = load_img(in_file).slicer[..., t_min:]\n",
    "\n",
    "    # Apply brain mask to functional image, reset header and save file as NIfTI\n",
    "    img_clean = math_img('img * mask[..., None]', img=img, mask=mask_file)\n",
    "    img_clean = new_img_like(img, img_clean.get_data(), copy_header=True)\n",
    "    img_clean.to_filename(out_file)\n",
    "\n",
    "    # Performe initial motion correction\n",
    "    res = MCFLIRT(mean_vol=True,\n",
    "                  save_plots=True,\n",
    "                  output_type='NIFTI',\n",
    "                  save_mats=True,\n",
    "                  in_file=out_file,\n",
    "                  out_file=out_file).run()\n",
    "\n",
    "    # Remove mcf file to save space\n",
    "    os.remove(out_file)\n",
    "        \n",
    "    # Aggregate outputs\n",
    "    outputs = [res.outputs.mean_img,\n",
    "               res.outputs.par_file,\n",
    "               dirname(res.outputs.mat_file[0])]\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "estimate_motion = Node(Function(input_names=['in_file', 'mask_file', 't_min'],\n",
    "                                  output_names=['mean_file', 'par_file', 'mat_folder'],\n",
    "                                  function=estimate_motion_parameters),\n",
    "                         name='estimate_motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply low-pass filters to motion parameters and prepare MAT-files\n",
    "def filter_motion_parameters(mean_file, par_file, mat_folder, tFilter, TR):\n",
    "\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from glob import glob\n",
    "    from math import cos, sin\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    from os.path import basename, abspath, exists\n",
    "    import subprocess\n",
    "    import warnings\n",
    "\n",
    "    # Specify name of output file\n",
    "    out_file = abspath(basename(par_file))\n",
    "    \n",
    "    # Collect MAT files\n",
    "    mat_file = sorted(glob('%s/MAT_????' % mat_folder))\n",
    "    new_mats = abspath('mats_files')\n",
    "    \n",
    "    # Function to low-pass filter FSL motion parameters\n",
    "    def clean_par(pars, TR, low_pass):\n",
    "\n",
    "        # Taken from nilearn.signal\n",
    "        def _check_wn(freq, nyq):\n",
    "            wn = freq / float(nyq)\n",
    "            if wn >= 1.:\n",
    "                wn = 1 - 10 * np.finfo(1.).eps\n",
    "                warnings.warn(\n",
    "                    'The frequency specified for the low pass filter is '\n",
    "                    'too high to be handled by a digital filter (superior to '\n",
    "                    'nyquist frequency). It has been lowered to %.2f (nyquist '\n",
    "                    'frequency).' % wn)\n",
    "            if wn < 0.0: # equal to 0.0 is okay\n",
    "                wn = np.finfo(1.).eps\n",
    "                warnings.warn(\n",
    "                    'The frequency specified for the low pass filter is too low'\n",
    "                    ' to be handled by a digital filter (must be non-negative).'\n",
    "                    ' It has been set to eps: %.5e' % wn)\n",
    "            return wn    \n",
    "\n",
    "        # Taken from nilearn.signal\n",
    "        def butterworth(signals, sampling_rate, low_pass, order=5):\n",
    "            nyq = sampling_rate * 0.5\n",
    "            critical_freq = _check_wn(low_pass, nyq)\n",
    "            b, a = butter(order, critical_freq, 'low', output='ba')\n",
    "            signals = filtfilt(b, a, signals, axis=0)\n",
    "            return signals\n",
    "\n",
    "        # Filter signal\n",
    "        pars_clean = butterworth(pars, 1./TR, low_pass)\n",
    "\n",
    "        return pars_clean\n",
    "\n",
    "\n",
    "    # Function to compute affine rotation matrix based on FSL rotation angles\n",
    "    def rot_mat(theta):\n",
    "\n",
    "        R_x = np.array([[1, 0,             0],\n",
    "                        [0, cos(theta[0]), sin(theta[0])],\n",
    "                        [0,-sin(theta[0]), cos(theta[0])]])\n",
    "\n",
    "        R_y = np.array([[cos(theta[1]), 0,-sin(theta[1])],\n",
    "                        [0,             1, 0],\n",
    "                        [sin(theta[1]), 0, cos(theta[1])]])\n",
    "\n",
    "        R_z = np.array([[ cos(theta[2]), sin(theta[2]), 0],\n",
    "                        [-sin(theta[2]), cos(theta[2]), 0],\n",
    "                        [ 0,             0,             1]])\n",
    "\n",
    "        return np.dot(R_z, np.dot(R_y, R_x))\n",
    "    \n",
    "    \n",
    "    # Perform second motion correction with low-pass filter if specified\n",
    "    if tFilter[0]:\n",
    "\n",
    "        # Extract low-pass filter value\n",
    "        low_pass = 1. / tFilter[0]\n",
    "\n",
    "        # Low-pass filter rotation angles\n",
    "        radi = np.loadtxt(par_file)[:, :3]\n",
    "        clean_radi = clean_par(radi, TR, low_pass)\n",
    "\n",
    "        #Extract translation parameters from FSL's MAT files\n",
    "        trans = []\n",
    "        for m in mat_file:\n",
    "            M = np.loadtxt(m)\n",
    "            R = M[:3,:3]\n",
    "\n",
    "            # Back-project translation parameters into origin space\n",
    "            trans.append(np.array(np.dot(np.linalg.inv(R), M[:3, -1])))\n",
    "\n",
    "        trans_o = np.array(trans)\n",
    "\n",
    "        # Low-pass filter translation parameters\n",
    "        clean_trans_o = clean_par(trans_o, TR, low_pass)\n",
    "        \n",
    "        # Create output folder for new MAT files\n",
    "        if not exists(new_mats):\n",
    "            os.makedirs(new_mats)\n",
    "\n",
    "        # Forward-project translation parameter into FSL space and save them\n",
    "        mat_files = []\n",
    "        clean_trans = []\n",
    "        for i, p in enumerate(clean_trans_o):\n",
    "            R = rot_mat(clean_radi[i])\n",
    "            tp = np.array(np.dot(R, clean_trans_o[i]))\n",
    "            clean_trans.append(tp)\n",
    "            mat = np.vstack((np.hstack((R, tp[..., None])), [0,0,0,1]))\n",
    "            new_mat_path = '%s/MAT_%04d' % (new_mats, i)\n",
    "            mat_files.append(new_mat_path)\n",
    "            np.savetxt(fname=new_mat_path, X=mat, delimiter=\" \", fmt='%.6f')\n",
    "            \n",
    "        # Overwrite FSL's pars file with new parameters\n",
    "        new_radi = []\n",
    "        new_trans = []\n",
    "\n",
    "        for m in mat_files:\n",
    "            cmd = 'avscale --allparams %s %s' % (m, mean_file)\n",
    "            process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "            pout = process.communicate()[0].decode(\"utf-8\").split('\\n')\n",
    "            for p in pout:\n",
    "                if 'Rotation Angles (x,y,z)' in p:\n",
    "                    new_radi.append(np.array(p[32:].split(), dtype='float'))\n",
    "                if 'Translations (x,y,z)' in p:\n",
    "                    new_trans.append(np.array(p[27:].split(), dtype='float'))\n",
    "        new_pars = np.hstack((new_radi, new_trans))\n",
    "        np.savetxt(out_file, new_pars, fmt='%.8e')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        out_file = abspath(basename(par_file))\n",
    "        np.savetxt(out_file, np.loadtxt(par_file), fmt='%.8e')\n",
    "        new_mats = mat_folder\n",
    "\n",
    "    return out_file, new_mats\n",
    "\n",
    "motion_parameters = Node(Function(input_names=['mean_file', 'par_file', 'mat_folder',\n",
    "                                               'tFilter', 'TR'],\n",
    "                                  output_names=['par_file', 'mat_folder'],\n",
    "                                  function=filter_motion_parameters),\n",
    "                         name='motion_parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for slice-wise acquisition\n",
    "def correct_for_slice_time(in_files, TR, slice_order, nslices,\n",
    "                           time_acquisition, ref_timepoint):\n",
    "    \n",
    "    import os\n",
    "    import numpy as np\n",
    "    from nilearn.image import load_img, new_img_like\n",
    "    from nipype.interfaces.spm import SliceTiming\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # Check if slice-time correction need to be performed or not\n",
    "    if len(np.unique(slice_order)) == 1:\n",
    "        timecorrected_files = in_files\n",
    "    else:\n",
    "    \n",
    "        # Specify name of output file and decompress it for SPM\n",
    "        out_file = abspath(basename(in_files).replace('.nii.gz', '_stc.nii'))\n",
    "        load_img(in_files).to_filename(out_file)\n",
    "\n",
    "        # Perform slice time correction\n",
    "        res = SliceTiming(in_files=out_file,\n",
    "                          ref_slice=ref_timepoint,\n",
    "                          time_repetition=TR,\n",
    "                          slice_order=slice_order,\n",
    "                          num_slices=nslices,\n",
    "                          time_acquisition=time_acquisition).run()\n",
    "        os.remove(out_file)\n",
    "        stc_file = res.outputs.timecorrected_files\n",
    "\n",
    "        # Reset TR value in header and compress output to reduce file size\n",
    "        timecorrected_files = stc_file.replace('.nii', '.nii.gz')\n",
    "        img_out = load_img(stc_file)\n",
    "        img_out = new_img_like(in_files, img_out.get_data(), copy_header=True)\n",
    "        img_out.header.set_zooms(list(img_out.header.get_zooms()[:3]) + [TR])\n",
    "        img_out.to_filename(timecorrected_files)\n",
    "        os.remove(stc_file)\n",
    "        \n",
    "    return timecorrected_files\n",
    "\n",
    "slice_time = Node(Function(input_names=['in_files', 'TR', 'slice_order', 'nslices',\n",
    "                                        'time_acquisition', 'ref_timepoint'],\n",
    "                              output_names=['timecorrected_files'],\n",
    "                              function=correct_for_slice_time),\n",
    "                     name='slice_time')\n",
    "slice_time.inputs.ref_timepoint = ref_timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply warp Motion Correction, Coregistration (and Normalization)\n",
    "def apply_warps(in_file, mat_folder, coreg, brain, transforms,\n",
    "                template, norm_func, t_min, TR):\n",
    "    \n",
    "    import os\n",
    "    import numpy as np\n",
    "    from glob import glob\n",
    "    from os.path import basename, abspath\n",
    "    from nipype.interfaces.ants import ApplyTransforms\n",
    "    from nipype.interfaces.c3 import C3dAffineTool\n",
    "    from nilearn.image import (iter_img, load_img, mean_img, concat_imgs,\n",
    "                               new_img_like, resample_to_img, threshold_img)\n",
    "    \n",
    "    # Specify name of output file and decompress it for SPM\n",
    "    out_file = abspath(basename(in_file.replace('.nii', '_warped.nii')))\n",
    "    if norm_func:\n",
    "        reference = template\n",
    "    else:\n",
    "        reference = 'temp_func.nii.gz'\n",
    "\n",
    "    # Apply warp for each volume individually\n",
    "    out_list = []\n",
    "    mat_files = sorted(glob(mat_folder + '/MAT_????'))\n",
    "\n",
    "    # Remove NSS volumes from functional image\n",
    "    img = load_img(in_file).slicer[..., t_min:]\n",
    "    \n",
    "    for i, e in enumerate(iter_img(img)):\n",
    "\n",
    "        temp_file = 'temp_func.nii.gz'\n",
    "        e.to_filename(temp_file)\n",
    "\n",
    "        c3d_coreg = C3dAffineTool(fsl2ras=True,\n",
    "                                  transform_file=coreg,\n",
    "                                  source_file='temp_func.nii.gz',\n",
    "                                  reference_file=brain,\n",
    "                                  itk_transform='temp_coreg.txt').run()\n",
    "\n",
    "        c3d_mc = C3dAffineTool(fsl2ras=True,\n",
    "                               transform_file=mat_files[i],\n",
    "                               source_file='temp_func.nii.gz',\n",
    "                               reference_file='temp_func.nii.gz',\n",
    "                               itk_transform='temp_mats.txt').run()\n",
    "\n",
    "        if norm_func:\n",
    "            transform_list = [transforms,\n",
    "                              c3d_coreg.outputs.itk_transform,\n",
    "                              c3d_mc.outputs.itk_transform]\n",
    "        else:\n",
    "            transform_list = [c3d_coreg.outputs.itk_transform,\n",
    "                              c3d_mc.outputs.itk_transform]\n",
    "\n",
    "        norm = ApplyTransforms(\n",
    "            input_image='temp_func.nii.gz',\n",
    "            reference_image=reference,\n",
    "            transforms=transform_list,\n",
    "            dimension=3,\n",
    "            float=True,\n",
    "            input_image_type=3,\n",
    "            interpolation='LanczosWindowedSinc',\n",
    "            invert_transform_flags=[False] * len(transform_list),\n",
    "            output_image='temp_out.nii.gz',\n",
    "            num_threads=1).run()\n",
    "\n",
    "        out_list.append(load_img(norm.outputs.output_image))\n",
    "        print(mat_files[i])\n",
    "\n",
    "    # Concatenate image and add TR value to header\n",
    "    imgs = concat_imgs(out_list)\n",
    "    imgs = new_img_like(reference, imgs.get_data(), copy_header=True)\n",
    "    imgs.header.set_zooms(list(imgs.header.get_zooms()[:3]) + [TR])\n",
    "    imgs.to_filename(out_file)\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "apply_warp = Node(Function(input_names=[\n",
    "    'in_file', 'mat_folder', 'coreg', 'brain', 'transforms',\n",
    "    'template', 'norm_func', 't_min', 'TR'],\n",
    "                              output_names=['out_file'],\n",
    "                              function=apply_warps),\n",
    "                     name='apply_warp')\n",
    "apply_warp.inputs.norm_func = norm_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image coregistration subworkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-alignment of functional images to anatomical image\n",
    "coreg_pre = Node(FLIRT(dof=6,\n",
    "                       output_type='NIFTI_GZ'),\n",
    "                 name='coreg_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coregistration of functional images to anatomical image with BBR\n",
    "# using WM segmentation\n",
    "coreg_bbr = Node(FLIRT(dof=9,\n",
    "                       cost='bbr',\n",
    "                       schedule=opj(os.getenv('FSLDIR'),\n",
    "                                    'etc/flirtsch/bbr.sch'),\n",
    "                       output_type='NIFTI_GZ'),\n",
    "                 name='coreg_bbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create coregistration workflow\n",
    "coregflow = Workflow(name='coregflow')\n",
    "\n",
    "# Add nodes to workflow and connect them\n",
    "coregflow.connect([(coreg_pre, coreg_bbr, [('out_matrix_file', 'in_matrix_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal and spatial filter subworkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create again a brain mask for the functional image and one for the confounds\n",
    "def create_warped_mask(in_file):\n",
    "\n",
    "    import numpy as np\n",
    "    from nipype.interfaces.fsl import BET\n",
    "    from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "    from nilearn.image import mean_img, new_img_like, load_img\n",
    "    from scipy.ndimage import binary_dilation, binary_erosion, binary_fill_holes\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # Compute mean image\n",
    "    mean_file = abspath(basename(in_file).replace('.nii', '_mean.nii'))\n",
    "    mean_img(in_file).to_filename(mean_file)\n",
    "\n",
    "    # Apply N4BiasFieldCorrection on mean file\n",
    "    res = N4BiasFieldCorrection(input_image=mean_file,\n",
    "                                dimension=3, copy_header=True).run()\n",
    "\n",
    "    # Create brain mask based on functional bias corrected mean file\n",
    "    res = BET(in_file=res.outputs.output_image, mask=True,\n",
    "              no_output=True, robust=True).run()\n",
    "\n",
    "    # Dilate the brain mask twice and fill wholes for functional mask\n",
    "    brain = load_img(res.outputs.mask_file).get_data()\n",
    "    mask_func = binary_fill_holes(binary_dilation(brain, iterations=2))\n",
    "\n",
    "    # Dilate brain mask once, fill wholes and erode twice for confound mask\n",
    "    mask_conf = binary_erosion(binary_fill_holes(\n",
    "            binary_dilation(brain, iterations=1)), iterations=2)\n",
    "\n",
    "    # Warping an image can induce noisy new voxels in the edge regions \n",
    "    # of a slab, which can be problematic for temporal filtering or\n",
    "    # later ICA. For this reason, we first drop any voxels that have\n",
    "    # zero-activation in more than 1% of all volumes and combine this\n",
    "    # with our previous brain mask\n",
    "    def remove_zero_voxels(in_file, bin_thr=1, vol_thr=0.99):\n",
    "        data = np.abs(load_img(in_file).get_data())\n",
    "        bins = np.histogram_bin_edges(np.ravel(data[data>0]), bins=100)\n",
    "        bin_cutoff = bins[bin_thr]\n",
    "        mask_zeros = np.sum(data>bin_cutoff, axis=-1)>(data.shape[-1] * vol_thr)\n",
    "        return binary_fill_holes(mask_zeros)\n",
    "\n",
    "    # Combine the functional brain mask with zero voxel mask and fill holes\n",
    "    mask_zeros = remove_zero_voxels(in_file, bin_thr=1, vol_thr=0.99)\n",
    "    data_mask = mask_zeros * mask_func\n",
    "    mask_func = binary_fill_holes(data_mask)\n",
    "\n",
    "    # Combine the confound brain mask with zero voxel mask, dilate once,\n",
    "    # fill wholes and erode twice\n",
    "    mask_zeros = remove_zero_voxels(in_file, bin_thr=5, vol_thr=0.95)\n",
    "    data_mask = mask_zeros * mask_conf\n",
    "    mask_conf = binary_erosion(binary_fill_holes(\n",
    "        binary_dilation(data_mask, iterations=1)), iterations=2)\n",
    "\n",
    "    # Save masks as NIfTI images\n",
    "    img_mask_func = new_img_like(in_file, mask_func.astype('int'),\n",
    "                                 copy_header=True)\n",
    "    mask_func = abspath(basename(in_file).replace('.nii', '_mask_func.nii'))\n",
    "    img_mask_func.to_filename(mask_func)\n",
    "\n",
    "    img_mask_conf = new_img_like(in_file, mask_conf.astype('int'),\n",
    "                                 copy_header=True)\n",
    "    mask_conf = abspath(basename(in_file).replace('.nii', '_mask_conf.nii'))\n",
    "    img_mask_conf.to_filename(mask_conf)\n",
    "\n",
    "    return mask_func, mask_conf\n",
    "\n",
    "masks_for_warp = Node(Function(input_names=['in_file'],\n",
    "                              output_names=['mask_func', 'mask_conf'],\n",
    "                              function=create_warped_mask),\n",
    "                     name='masks_for_warp')\n",
    "masks_for_warp.inputs.norm_func = norm_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply temporal filter to functional image\n",
    "def apply_temporal_filter(in_file, mask, tFilter, tr):\n",
    "\n",
    "    import numpy as np\n",
    "    from nipype.interfaces.afni import Bandpass\n",
    "    from nilearn.image import load_img, math_img, mean_img, new_img_like\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # Extract low- and high-pass filter\n",
    "    low_pass = tFilter[0]\n",
    "    high_pass = tFilter[1]\n",
    "    lowpass = 1. / low_pass if low_pass != None else 999999\n",
    "    highpass = 1. / high_pass if high_pass != None else 0\n",
    "\n",
    "    # Temporal filtering to get rid of high and/or low-pass frequencies\n",
    "    res = Bandpass(in_file=in_file,\n",
    "                   mask=mask,\n",
    "                   lowpass=lowpass,\n",
    "                   highpass=highpass,\n",
    "                   tr=tr,\n",
    "                   num_threads=-1,\n",
    "                   no_detrend=True,\n",
    "                   outputtype='NIFTI_GZ').run()\n",
    "    \n",
    "    # Add mean image back to functional image and apply mask\n",
    "    img_mean = mean_img(in_file)\n",
    "    img_out = math_img(\n",
    "        '(img + mean[..., None]) * mask[..., None]', mask=mask,\n",
    "        img=res.outputs.out_file, mean=img_mean)\n",
    "\n",
    "    # Intensity normalize image to the white matter histogram density peak\n",
    "    img_mean = mean_img(img_out)\n",
    "    count, bins = np.histogram(np.ravel(np.abs(img_mean.get_data())), bins=128)\n",
    "    sigma = bins[32 + np.argmax(count[32:])]\n",
    "    sigma /= 10000\n",
    "    data = img_out.get_data() / sigma\n",
    "\n",
    "    # Save output into NIfTI file\n",
    "    img_out = new_img_like(in_file, data, copy_header=True)\n",
    "    out_file = abspath(basename(in_file).replace('.nii', '_tf.nii'))\n",
    "    img_out.to_filename(out_file)\n",
    "\n",
    "    mean_file = abspath(basename(in_file).replace('.nii', '_tf_mean.nii'))\n",
    "    img_mean.to_filename(mean_file)\n",
    "    \n",
    "    return out_file, mean_file\n",
    "\n",
    "temporal_filter = Node(Function(input_names=['in_file', 'mask', 'tFilter', 'tr'],\n",
    "                                 output_names=['out_file', 'mean_file'],\n",
    "                                 function=apply_temporal_filter),\n",
    "                        name='temporal_filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies gaussian spatial filter as in Sengupta, Pollmann & Hanke, 2018\n",
    "def gaussian_spatial_filter(in_file, sFilter, mask, bandwidth=2):\n",
    "\n",
    "    import numpy as np\n",
    "    from nilearn.image import load_img, smooth_img, math_img, new_img_like\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # Extract smoothing type and FWHM value\n",
    "    ftype, fwhm = sFilter\n",
    "    \n",
    "    if fwhm == 0:\n",
    "        img = load_img(in_file)\n",
    "\n",
    "    elif ftype == 'LP':\n",
    "        img = smooth_img(in_file, fwhm=fwhm)\n",
    "        \n",
    "    elif ftype == 'HP':\n",
    "        img_smooth = smooth_img(in_file, fwhm=fwhm)\n",
    "        img = math_img('img1 - img2', img1=img_smooth, img2=in_file)\n",
    "        \n",
    "    elif ftype == 'BP':\n",
    "        img_smooth_high = smooth_img(in_file, fwhm=fwhm)\n",
    "        img_smooth_low = smooth_img(in_file, fwhm=fwhm - bandwidth)\n",
    "        img = math_img('img1 - img2', img1=img_smooth_high, img2=img_smooth_low)\n",
    "\n",
    "    # Mask smoothed image\n",
    "    mask = load_img(mask).get_data()\n",
    "    data = img.get_data() * mask[..., None]\n",
    "        \n",
    "    # Before we can save the final output NIfTI in 'int16' format, we need\n",
    "    # to make sure that there's no data overflow, i.e. values above 32768\n",
    "    data = img.get_data()\n",
    "    max_value = 30000\n",
    "    max_data = np.max(np.abs(data))\n",
    "    if max_data > max_value:\n",
    "        data /= max_data\n",
    "        data *= max_value\n",
    "        print('Max-value was adapted: From %f to %f' % (max_data, max_value))\n",
    "    \n",
    "    # Now we can reset the header and save image to file with data type 'int'\n",
    "    out_img = new_img_like(in_file, data.astype('int16'), copy_header=True)\n",
    "    out_img.set_data_dtype('int16')   \n",
    "    out_file = abspath(basename(in_file).replace('.nii', '_%s_%smm.nii' % (ftype, fwhm)))\n",
    "    out_img.to_filename(out_file)\n",
    "\n",
    "    return out_file\n",
    "\n",
    "# Spatial Band-Pass Filter\n",
    "spatial_filter = Node(Function(input_names=['in_file', 'sFilter', 'mask'],\n",
    "                               output_names=['out_file'],\n",
    "                               function=gaussian_spatial_filter),\n",
    "                      name='spatial_filter')\n",
    "spatial_filter.iterables = ('sFilter', filters_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal and spatial filter workflow\n",
    "filterflow = Workflow(name='filterflow')\n",
    "\n",
    "# Add nodes to workflow and connect them\n",
    "filterflow.connect([(masks_for_warp, temporal_filter, [('mask_func', 'mask')]),\n",
    "                    (masks_for_warp, spatial_filter, [('mask_func', 'mask')]),\n",
    "                    (temporal_filter, spatial_filter, [('out_file', 'in_file')]),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Main Workflow\n",
    "\n",
    "**Note:** Slice time correction is applied after motion correction, as recommended by Power et al. (2017): http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0182939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main preprocessing workflow\n",
    "mainflow = Workflow(name='mainflow')\n",
    "\n",
    "# Add nodes to workflow and connect them\n",
    "mainflow.connect([(prepareflow, estimate_motion, [('reorient.out_file', 'in_file'),\n",
    "                                                  ('mask_func_brain.mask_file', 'mask_file'),\n",
    "                                                  ('nss_detection.t_min', 't_min'),\n",
    "                                                 ]),\n",
    "                  (estimate_motion, motion_parameters, [('mean_file', 'mean_file'),\n",
    "                                                        ('par_file', 'par_file'),\n",
    "                                                        ('mat_folder', 'mat_folder')]),\n",
    "                  (prepareflow, slice_time, [('reorient.out_file', 'in_files')]),\n",
    "                  (slice_time, apply_warp, [('timecorrected_files', 'in_file')]),\n",
    "                  (prepareflow, apply_warp, [('nss_detection.t_min', 't_min')]),\n",
    "                  (estimate_motion, coregflow, [('mean_file', 'coreg_pre.in_file'),\n",
    "                                                ('mean_file', 'coreg_bbr.in_file')]),\n",
    "                  (coregflow, apply_warp, [('coreg_bbr.out_matrix_file', 'coreg')]),\n",
    "                  (motion_parameters, apply_warp, [('mat_folder', 'mat_folder')]),\n",
    "                  (apply_warp, filterflow, [('out_file', 'masks_for_warp.in_file'),\n",
    "                                            ('out_file', 'temporal_filter.in_file')]),\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a subworkflow for the Confound Workflow\n",
    "\n",
    "### Implement Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ACompCor (based on Behzadi et al., 2007)\n",
    "aCompCor = Node(ACompCor(num_components=n_compcor_confounds,\n",
    "                         pre_filter='cosine',\n",
    "                         save_pre_filter=False,\n",
    "                         merge_method='union',\n",
    "                         components_file='compcorA.txt'),\n",
    "                name='aCompCor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary mask for ACompCor (based on Behzadi et al., 2007)\n",
    "def get_csf_wm_mask(mean_file, wm, csf, brainmask, \n",
    "                    temp_wm, temp_csf, norm_func):\n",
    "\n",
    "    from os.path import basename, abspath\n",
    "    from nilearn.image import load_img, threshold_img, resample_to_img, new_img_like\n",
    "    from scipy.ndimage.morphology import binary_erosion, binary_closing\n",
    "\n",
    "    # Specify name of output file\n",
    "    out_file = abspath(basename(mean_file).replace('.nii', '_maskA.nii'))\n",
    "    \n",
    "    if norm_func:\n",
    "\n",
    "        # Create eroded WM binary mask\n",
    "        bin_wm = threshold_img(temp_wm, 0.5)\n",
    "        mask_wm = binary_erosion(bin_wm.get_data(), iterations=2).astype('int8')\n",
    "\n",
    "        # Create eroded CSF binary mask (differs from Behzadi et al., 2007)\n",
    "        bin_csf = threshold_img(temp_csf, 0.5)\n",
    "        close_csf = binary_closing(bin_csf.get_data(), iterations=1)\n",
    "        mask_csf = binary_erosion(close_csf, iterations=1).astype('int8')\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        # Create eroded WM binary mask\n",
    "        thr_wm = resample_to_img(threshold_img(wm, 0.99), mean_file)\n",
    "        bin_wm = threshold_img(thr_wm, 0.5)\n",
    "        mask_wm = binary_erosion(bin_wm.get_data(), iterations=2).astype('int8')\n",
    "\n",
    "        # Create eroded CSF binary mask (differs from Behzadi et al., 2007)\n",
    "        thr_csf = resample_to_img(threshold_img(csf, 0.99), mean_file)\n",
    "        bin_csf = threshold_img(thr_csf, 0.5)\n",
    "        close_csf = binary_closing(bin_csf.get_data(), iterations=1)\n",
    "        mask_csf = binary_erosion(close_csf, iterations=1).astype('int8')\n",
    "\n",
    "    # Load brain mask\n",
    "    mask_brain = load_img(brainmask).get_data()\n",
    "\n",
    "    # Combine WM and CSF binary masks into one and apply brainmask\n",
    "    binary_mask = (((mask_wm + mask_csf) * mask_brain) > 0).astype('int8')\n",
    "    mask_img = new_img_like(mean_file, binary_mask.astype('int16'), copy_header=True)\n",
    "    mask_img.to_filename(out_file)\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "acomp_masks = Node(Function(input_names=['mean_file', 'wm', 'csf', 'brainmask',\n",
    "                                         'temp_wm', 'temp_csf', 'norm_func'],\n",
    "                            output_names=['out_file'],\n",
    "                            function=get_csf_wm_mask),\n",
    "                   name='acomp_masks')\n",
    "acomp_masks.inputs.norm_func = norm_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TCompCor (based on Behzadi et al., 2007)\n",
    "tCompCor = Node(TCompCor(num_components=n_compcor_confounds,\n",
    "                         percentile_threshold=0.02,\n",
    "                         pre_filter='cosine',\n",
    "                         save_pre_filter=False,\n",
    "                         components_file='compcorT.txt'),\n",
    "                name='tCompCor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ICA components\n",
    "def extract_ica_components(in_file, mask_file, n_components):\n",
    "    \n",
    "    import numpy as np\n",
    "    from nilearn.image import load_img\n",
    "    from scipy.stats import zscore, pearsonr\n",
    "    from nilearn.decomposition import CanICA\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # Load functiona image and mask\n",
    "    img = load_img(in_file)\n",
    "    img_mask= load_img(mask_file)\n",
    "\n",
    "    # Compute average inplane resolution for light smoothing\n",
    "    fwhm = np.mean(img.header.get_zooms()[:2])\n",
    "\n",
    "    # Specify CanICA object\n",
    "    canica = CanICA(n_components=n_components, smoothing_fwhm=fwhm,\n",
    "                    mask=mask_file, threshold='auto', n_jobs=1,\n",
    "                    standardize=True, detrend=True)\n",
    "\n",
    "    # Fit CanICA on input data\n",
    "    canica.fit(img)\n",
    "    \n",
    "    # Save components into NIfTI file\n",
    "    comp_file = abspath(basename(in_file).replace('.nii', '_ICA_comp.nii'))\n",
    "    img_comp = canica.components_img_\n",
    "    img_comp.to_filename(comp_file)\n",
    "\n",
    "    # Extract data and mask from images\n",
    "    data = img.get_data()\n",
    "    mask = img_mask.get_data()!=0\n",
    "\n",
    "    # Compute the pearson correlation between the components and the signal\n",
    "    curves = zscore([[pearsonr(img_comp.get_data()[mask, j],\n",
    "                               data[mask, i])[0] for i in range(data.shape[-1])]\n",
    "                     for j in range(n_components)], axis=-1)\n",
    "    comp_signal = abspath(basename(in_file).replace('.nii.gz', '_ICA_comp.txt'))\n",
    "    np.savetxt(comp_signal, curves, fmt='%.8e', delimiter=' ', newline='\\n')\n",
    "\n",
    "    return comp_file, comp_signal\n",
    "\n",
    "compute_ica = Node(Function(input_names=['in_file', 'mask_file', 'n_components'],\n",
    "                            output_names=['comp_file', 'comp_signal'],\n",
    "                            function=extract_ica_components),\n",
    "                   name='compute_ica')\n",
    "compute_ica.inputs.n_components = n_independent_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute framewise displacement (FD)\n",
    "FD = Node(FramewiseDisplacement(parameter_source='FSL',\n",
    "                                normalize=False),\n",
    "          name='FD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute DVARS\n",
    "dvars = Node(ComputeDVARS(remove_zerovariance=True,\n",
    "                          save_vxstd=True),\n",
    "             name='dvars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes Friston 24-parameter model (Friston et al., 1996)\n",
    "def compute_friston24(in_file):\n",
    "    \n",
    "    import numpy as np\n",
    "    from os.path import basename, abspath\n",
    "    \n",
    "    # Load raw motion parameters\n",
    "    mp_raw = np.loadtxt(in_file)\n",
    "    \n",
    "    # Get motion paremter one time point before (first order difference)\n",
    "    mp_minus1 = np.vstack(([0] * 6, mp_raw[1:]))\n",
    "    \n",
    "    # Combine the two\n",
    "    mp_combine = np.hstack((mp_raw, mp_minus1))\n",
    "\n",
    "    # Add the square of those parameters to allow correction of nonlinear effects\n",
    "    mp_friston = np.hstack((mp_combine, mp_combine**2))\n",
    "\n",
    "    # Save friston 24-parameter model in new txt file\n",
    "    out_file = abspath(basename(in_file).replace('.txt', 'friston24.txt'))\n",
    "    np.savetxt(out_file, mp_friston,\n",
    "               fmt='%.8e', delimiter=' ', newline='\\n')\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "friston24 = Node(Function(input_names=['in_file'],\n",
    "                          output_names=['out_file'],\n",
    "                          function=compute_friston24),\n",
    "                 name='friston24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average signal in total volume, in GM, in WM and in CSF\n",
    "def get_average_signal(in_file, gm, wm, csf, brainmask, template_file,\n",
    "                       temp_mask, temp_gm, temp_wm, temp_csf, norm_func):\n",
    "\n",
    "    from scipy.stats import zscore\n",
    "    from nilearn.image import load_img, threshold_img, resample_to_img, math_img\n",
    "    from nilearn.masking import apply_mask\n",
    "\n",
    "    if norm_func:\n",
    "        res_brain = temp_mask\n",
    "        res_gm = threshold_img(temp_gm, 0.99)\n",
    "        res_wm = threshold_img(temp_wm, 0.99)\n",
    "        res_csf = threshold_img(temp_csf, 0.99)\n",
    "        \n",
    "    else:\n",
    "        res_brain = resample_to_img(brainmask, template_file)\n",
    "        res_gm = resample_to_img(threshold_img(gm, 0.99), template_file)\n",
    "        res_wm = resample_to_img(threshold_img(wm, 0.99), template_file)\n",
    "        res_csf = resample_to_img(threshold_img(csf, 0.99), template_file)\n",
    "\n",
    "    \n",
    "    # Create masks for signal extraction\n",
    "    bin_brain = math_img('(mask>=0.5) * template',\n",
    "                         mask=res_brain, template=template_file)\n",
    "    bin_gm = math_img('(mask>=0.5) * template',\n",
    "                      mask=res_gm, template=template_file)\n",
    "    bin_wm = math_img('(mask>=0.5) * template',\n",
    "                      mask=res_wm, template=template_file)\n",
    "    bin_csf = math_img('(mask>=0.5) * template',\n",
    "                       mask=res_csf, template=template_file)\n",
    "\n",
    "    # Load data from functional image and zscore it\n",
    "    img = load_img(in_file)\n",
    "\n",
    "    # Compute average signal per mask and zscore timeserie\n",
    "    signal_gm = zscore(apply_mask(img, bin_gm).mean(axis=1))\n",
    "    signal_wm = zscore(apply_mask(img, bin_wm).mean(axis=1))\n",
    "    signal_csf = zscore(apply_mask(img, bin_csf).mean(axis=1))\n",
    "    signal_brain = zscore(apply_mask(img, bin_brain).mean(axis=1))\n",
    "\n",
    "    return [signal_brain, signal_gm, signal_wm, signal_csf]\n",
    "\n",
    "average_signal = Node(Function(input_names=[\n",
    "    'in_file', 'gm', 'wm', 'csf', 'brainmask', 'template_file',\n",
    "    'temp_mask', 'temp_gm', 'temp_wm', 'temp_csf', 'norm_func'],\n",
    "                               output_names=['average'],\n",
    "                               function=get_average_signal),\n",
    "                      name='average_signal')\n",
    "average_signal.inputs.norm_func = norm_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine confound parameters into one TSV file\n",
    "def consolidate_confounds(FD, DVARS, par_mc, par_mc_raw, par_friston,\n",
    "                          compA, compT, average, ica_comp):\n",
    "    \n",
    "    import numpy as np\n",
    "    from os.path import basename, abspath\n",
    "    \n",
    "    conf_FD = np.array([0] + list(np.loadtxt(FD, skiprows=1)))\n",
    "    conf_DVARS = np.array([1] + list(np.loadtxt(DVARS, skiprows=0)))\n",
    "    conf_mc = np.loadtxt(par_mc)\n",
    "    conf_mc_raw = np.loadtxt(par_mc_raw)\n",
    "    conf_friston = np.loadtxt(par_friston)\n",
    "    conf_compA = np.loadtxt(compA, skiprows=1)\n",
    "    conf_compT = np.loadtxt(compT, skiprows=1)\n",
    "    conf_average = np.array(average)\n",
    "    conf_ica = np.loadtxt(ica_comp).T\n",
    "\n",
    "    # Aggregate confounds\n",
    "    confounds = np.hstack((conf_FD[..., None],\n",
    "                           conf_DVARS[..., None],\n",
    "                           conf_average.T,\n",
    "                           conf_mc,\n",
    "                           conf_mc_raw,\n",
    "                           conf_friston,\n",
    "                           conf_ica,\n",
    "                           conf_compA,\n",
    "                           conf_compT))\n",
    "\n",
    "    # Create header\n",
    "    header = ['FD', 'DVARS']\n",
    "    header += ['TV', 'GM', 'WM', 'CSF']\n",
    "    header += ['Rotation%02d' % (d + 1) for d in range(3)]\n",
    "    header += ['Translation%02d' % (d + 1) for d in range(3)]\n",
    "    header += ['Rotation%02d_raw' % (d + 1) for d in range(3)]\n",
    "    header += ['Translation%02d_raw' % (d + 1) for d in range(3)]\n",
    "    header += ['Friston%02d' % (d + 1) for d in range(conf_friston.shape[1])]\n",
    "    header += ['ICA%02d' % (d + 1) for d in range(conf_ica.shape[1])]\n",
    "    header += ['CompA%02d' % (d + 1) for d in range(conf_compA.shape[1])]\n",
    "    header += ['CompT%02d' % (d + 1) for d in range(conf_compT.shape[1])]\n",
    "\n",
    "    # Write to file\n",
    "    out_file = abspath(basename(par_mc).replace('.par', '_confounds.tsv'))\n",
    "    with open(out_file, 'w') as f:\n",
    "        f.write('\\t'.join(header) + '\\n')\n",
    "        for row in confounds:\n",
    "            f.write('\\t'.join([str(r) for r in row]) + '\\n')\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "combine_confounds = Node(Function(input_names=['FD', 'DVARS', 'par_mc', 'par_mc_raw',\n",
    "                                               'par_friston', 'compA', 'compT',\n",
    "                                               'average', 'ica_comp'],\n",
    "                                  output_names=['out_file'],\n",
    "                                  function=consolidate_confounds),\n",
    "                         name='combine_confounds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Confound Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confound extraction workflow\n",
    "confflow = Workflow(name='confflow')\n",
    "\n",
    "# Add nodes to workflow and connect them\n",
    "confflow.connect([(acomp_masks, aCompCor, [('out_file', 'mask_files')]),\n",
    "\n",
    "                  # Consolidate confounds\n",
    "                  (FD, combine_confounds, [('out_file', 'FD')]),\n",
    "                  (dvars, combine_confounds, [('out_vxstd', 'DVARS')]),\n",
    "                  (aCompCor, combine_confounds, [('components_file', 'compA')]),\n",
    "                  (tCompCor, combine_confounds, [('components_file', 'compT')]),\n",
    "                  (friston24, combine_confounds, [('out_file', 'par_friston')]),\n",
    "                  (average_signal, combine_confounds, [('average', 'average')]),\n",
    "                  (compute_ica, combine_confounds, [('comp_signal', 'ica_comp')]),\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a subworkflow for the report Workflow\n",
    "\n",
    "### Implement Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean image with brainmask and ACompCor and TCompCor mask ovleray\n",
    "def plot_masks(sub_id, ses_id, task_id, run_id, mean, maskA, maskT, brainmask):\n",
    "    \n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from matplotlib.pyplot import figure\n",
    "    from nilearn.plotting import plot_roi, find_cut_slices\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # If needed, create title for output figures\n",
    "    title_txt = 'Sub: %s - Task: %s' % (sub_id, task_id)\n",
    "    if ses_id:\n",
    "        title_txt += ' - Sess: %s' % ses_id\n",
    "    if run_id:\n",
    "        title_txt += ' - Run: %d' % run_id\n",
    "\n",
    "    # Establish name of output file\n",
    "    out_file = basename(mean).replace('_mean.nii.gz', '_overlays.png')\n",
    "\n",
    "    # Prepare maskA, maskT and brainmask (otherwise they create strange looking outputs)\n",
    "    img = nb.load(mean)\n",
    "    data = np.stack((np.zeros(img.shape),\n",
    "                    nb.load(brainmask).get_data(),\n",
    "                    nb.load(maskA).get_data() * 2,\n",
    "                    nb.load(maskT).get_data() * 3),\n",
    "                    axis= -1)\n",
    "    label_id = np.argmax(data, axis=-1)\n",
    "    masks = nb.Nifti1Image(label_id, img.affine, img.header)\n",
    "\n",
    "    # Get content extent of mean img and crop all images with it\n",
    "    content = np.nonzero(img.get_data())\n",
    "    c = np.ravel([z for z in zip(np.min(content, axis=1), np.max(content, axis=1))])\n",
    "    img = img.slicer[c[0]:c[1], c[2]:c[3], c[4]:c[5]]\n",
    "    masks = masks.slicer[c[0]:c[1], c[2]:c[3], c[4]:c[5]]\n",
    "\n",
    "    # Plot functional mean and different masks used (compcor and brainmask)\n",
    "    fig = figure(figsize=(16, 8))\n",
    "\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    colormap = ListedColormap([(0.86, 0.3712, 0.34),\n",
    "                               (0.3712, 0.34, 0.86),\n",
    "                               (0.34, 0.86, 0.3712)])\n",
    "\n",
    "    for i, e in enumerate(['x', 'y', 'z']):\n",
    "        ax = fig.add_subplot(3, 1, i + 1)\n",
    "        cuts = find_cut_slices(img, direction=e, n_cuts=10)[1:-1]\n",
    "        plot_roi(masks, cmap=colormap, dim=1, annotate=False, bg_img=img,\n",
    "                 display_mode=e, title=title_txt + ' - %s-axis' % e,\n",
    "                 resampling_interpolation='nearest', cut_coords=cuts,\n",
    "                 axes=ax, alpha=0.66)\n",
    "\n",
    "    # Establish name of output file\n",
    "    out_file = abspath(basename(mean).replace('_mean.nii.gz', '_overlays.png'))\n",
    "    fig.savefig(out_file, bbox_inches='tight', facecolor='black',\n",
    "                frameon=True, dpi=300, transparent=False)\n",
    "\n",
    "    return out_file\n",
    "\n",
    "compcor_plot = Node(Function(input_names=['sub_id', 'ses_id', 'task_id', 'run_id',\n",
    "                                          'mean', 'maskA', 'maskT', 'brainmask'],\n",
    "                             output_names=['out_file'],\n",
    "                             function=plot_masks),\n",
    "                    name='compcor_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confounds and detect outliers\n",
    "def plot_confounds(confounds, outlier_thr):\n",
    "\n",
    "    # This plotting is heavily based on MRIQC's visual reports (credit to oesteban)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy.stats import zscore\n",
    "    from matplotlib.backends.backend_pdf import FigureCanvasPdf as FigureCanvas\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    def plot_timeseries(dataframe, elements, out_file, outlier_thr=None, motion=False):\n",
    "\n",
    "        # Number of rows to plot\n",
    "        n_rows = len(elements)\n",
    "\n",
    "        # Prepare for motion plot\n",
    "        if motion:\n",
    "            n_rows = int(n_rows / 2)\n",
    "\n",
    "        # Create canvas\n",
    "        fig = plt.Figure(figsize=(16, 2 * n_rows))\n",
    "        FigureCanvas(fig)\n",
    "        grid = GridSpec(n_rows, 2, width_ratios=[7, 1])\n",
    "\n",
    "        # Specify color palette to use\n",
    "        colors = sns.husl_palette(n_rows)\n",
    "\n",
    "        # To collect possible outlier indices\n",
    "        outlier_idx = []\n",
    "\n",
    "        # Plot timeseries (and detect outliers, if specified)\n",
    "        for i, e in enumerate(elements[:n_rows]):\n",
    "\n",
    "            # Extract timeserie values\n",
    "            data = dataframe[e].values\n",
    "\n",
    "            # Z-score data for later thresholding\n",
    "            zdata = zscore(data)\n",
    "\n",
    "            # Plot timeserie\n",
    "            ax = fig.add_subplot(grid[i, :-1])\n",
    "            if motion:\n",
    "                ax.plot(dataframe[e + '_raw'].values, color=[0.66] * 3)\n",
    "            ax.plot(data, color=colors[i])\n",
    "            ax.set_xlim((0, len(data)))\n",
    "            ax.set_ylabel(e)\n",
    "            ylim = ax.get_ylim()\n",
    "\n",
    "            # Detect and plot outliers if threshold is specified\n",
    "            if outlier_thr:\n",
    "\n",
    "                threshold = outlier_thr[i]\n",
    "\n",
    "                if threshold != None:\n",
    "\n",
    "                    outlier_id = np.where(np.abs(zdata)>=threshold)[0]\n",
    "                    outlier_idx += list(outlier_id)\n",
    "                    ax.vlines(outlier_id, ylim[0], ylim[1])\n",
    "\n",
    "            # Plot observation distribution\n",
    "            ax = fig.add_subplot(grid[i, -1])\n",
    "            sns.distplot(data, vertical=True, ax=ax, color=colors[i])\n",
    "            ax.set_ylim(ylim)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(out_file)\n",
    "\n",
    "        return np.unique(outlier_idx)\n",
    "\n",
    "    # Load confounds table\n",
    "    df = pd.read_csv(confounds, sep='\t')\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Aggregate output plots\n",
    "    out_plots = []\n",
    "    confounds = basename(confounds)\n",
    "    \n",
    "    # Plot main confounds\n",
    "    elements = ['FD', 'DVARS', 'TV', 'GM', 'WM', 'CSF']\n",
    "    out_file = abspath(confounds.replace('.tsv', '_main.png'))\n",
    "    out_plots.append(out_file)\n",
    "    outliers = plot_timeseries(df, elements, out_file, outlier_thr)\n",
    "    \n",
    "    # Save outlier indices to textfile\n",
    "    outlier_filename = abspath(confounds.replace('.tsv', '_outliers.txt'))\n",
    "    np.savetxt(outlier_filename, outliers, fmt='%d')\n",
    "\n",
    "    # Plot Motion Paramters\n",
    "    elements = [k for k in df.keys() if 'Rotation' in k or 'Translation' in k]\n",
    "    out_file = abspath(confounds.replace('.tsv', '_motion.png'))\n",
    "    out_plots.append(out_file)\n",
    "    plot_timeseries(df, elements, out_file, motion=True)\n",
    "\n",
    "    # Plot CompCor components\n",
    "    for comp in ['A', 'T']:\n",
    "        elements = [k for k in df.keys() if 'Comp%s' % comp in k]\n",
    "        out_file = abspath(confounds.replace('.tsv', '_comp%s.png' % comp))\n",
    "        out_plots.append(out_file)\n",
    "        plot_timeseries(df, elements, out_file)\n",
    "    \n",
    "    # Reset seaborn\n",
    "    sns.reset_orig()\n",
    "\n",
    "    return [outlier_filename] + out_plots\n",
    "\n",
    "confound_inspection = Node(Function(input_names=['confounds', 'outlier_thr'],\n",
    "                                    output_names=['outlier_file', 'plot_main', 'plot_motion',\n",
    "                                                  'plot_compA', 'plot_compT'],\n",
    "                                    function=plot_confounds),\n",
    "                           name='confound_inspection')\n",
    "confound_inspection.inputs.outlier_thr = outlier_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates carpet plot\n",
    "def create_carpet_plot(in_file, sub_id, ses_id, task_id, run_id, \n",
    "                       seg_gm, seg_wm, seg_csf, nVoxels, brainmask):\n",
    "\n",
    "    from os.path import basename, abspath\n",
    "    from nilearn.image import load_img, resample_to_img\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import zscore\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Load functional image and mask\n",
    "    img = load_img(in_file)\n",
    "    data = img.get_data()\n",
    "    mask = load_img(brainmask).get_data()\n",
    "\n",
    "    # Resample masks to functional space and threshold them\n",
    "    mask_gm = resample_to_img(seg_gm, img, interpolation='nearest').get_data() >= 0.5\n",
    "    mask_wm = resample_to_img(seg_wm, img, interpolation='nearest').get_data() >= 0.5\n",
    "    mask_csf = resample_to_img(seg_csf, img, interpolation='nearest').get_data() >= 0.5\n",
    "\n",
    "    # Restrict signal to plot to specific mask\n",
    "    data_gm = data[(mask_gm * mask).astype('bool')]\n",
    "    data_wm = data[(mask_wm * mask).astype('bool')]\n",
    "    data_csf = data[(mask_csf * mask).astype('bool')]\n",
    "\n",
    "    # Remove voxels without any variation over time\n",
    "    data_gm = data_gm[data_gm.std(axis=-1)!=0]\n",
    "    data_wm = data_wm[data_wm.std(axis=-1)!=0]\n",
    "    data_csf = data_csf[data_csf.std(axis=-1)!=0]\n",
    "\n",
    "    # Compute stepsize and reduce datasets\n",
    "    stepsize = int((len(data_gm) + len(data_wm) + len(data_csf)) / nVoxels)\n",
    "    data_gm = data_gm[::stepsize]\n",
    "    data_wm = data_wm[::stepsize]\n",
    "    data_csf = data_csf[::stepsize]\n",
    "\n",
    "    # Sort voxels according to correlation to mean signal within a ROI\n",
    "    data_gm = data_gm[np.argsort([np.corrcoef(d, data_gm.mean(axis=0))[0, 1] for d in data_gm])]\n",
    "    data_wm = data_wm[np.argsort([np.corrcoef(d, data_wm.mean(axis=0))[0, 1] for d in data_wm])]\n",
    "    data_csf = data_csf[np.argsort([np.corrcoef(d, data_csf.mean(axis=0))[0, 1] for d in data_csf])]\n",
    "\n",
    "    # Create carpet plot, zscore and rescale it\n",
    "    carpet = np.row_stack((data_gm, data_wm, data_csf))\n",
    "    carpet = np.nan_to_num(zscore(carpet, axis=-1))\n",
    "    carpet /= np.abs(carpet).max(axis=0)\n",
    "\n",
    "    # Create title for figure\n",
    "    title_txt = 'Sub: %s - Task: %s' % (sub_id, task_id)\n",
    "    if ses_id:\n",
    "        title_txt += ' - Sess: %s' % ses_id\n",
    "    if run_id:\n",
    "        title_txt += ' - Run: %d' % run_id\n",
    "    \n",
    "    # Plot carpet plot and save it\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(carpet, aspect='auto', cmap='gray')\n",
    "    plt.hlines((data_gm.shape[0]), 0, carpet.shape[1] - 1, colors='r')\n",
    "    plt.hlines((data_gm.shape[0] + data_wm.shape[0]), 0, carpet.shape[1] - 1, colors='b')\n",
    "    plt.title(title_txt)\n",
    "    plt.xlabel('Volume')\n",
    "    plt.ylabel('Voxel')\n",
    "    plt.tight_layout()\n",
    "    out_file = abspath(basename(in_file).replace('.nii.gz', '_carpet.png'))\n",
    "    fig.savefig(out_file)\n",
    "\n",
    "    # Reset seaborn\n",
    "    sns.reset_orig()\n",
    "\n",
    "    return out_file\n",
    "\n",
    "carpet_plot = Node(Function(input_names=['in_file', 'sub_id', 'ses_id', 'task_id', 'run_id',\n",
    "                                         'seg_gm', 'seg_wm', 'seg_csf', 'nVoxels', 'brainmask'],\n",
    "                            output_names=['out_file'],\n",
    "                            function=create_carpet_plot),\n",
    "                   name='carpet_plot')\n",
    "carpet_plot.inputs.nVoxels = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates carpet plot\n",
    "def plot_ica_components(comp_signal, comp_file, mean_file, TR):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.backends.backend_pdf import FigureCanvasPdf as FigureCanvas\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    import numpy as np\n",
    "    from nilearn.image import iter_img, load_img, coord_transform\n",
    "    from nilearn.plotting import plot_stat_map, find_cut_slices\n",
    "    from scipy.signal import welch\n",
    "    from os.path import basename, abspath\n",
    "\n",
    "    # Read data\n",
    "    img_comp = load_img(comp_file)\n",
    "    comp_data = np.loadtxt(comp_signal)\n",
    "    n_components = comp_data.shape[0]\n",
    "    elements = ['ICA%02d' % (d + 1) for d in range(n_components)]\n",
    "\n",
    "    # Plot singal components and their power spectrum density maps\n",
    "    fig = plt.Figure(figsize=(16, 2 * n_components))\n",
    "    FigureCanvas(fig)\n",
    "    grid = GridSpec(n_components, 2, width_ratios=[6, 2])\n",
    "\n",
    "    # Specify color palette to use\n",
    "    colors = sns.husl_palette(n_components)\n",
    "\n",
    "    # Plot timeseries\n",
    "    freq, power_spectrum = welch(comp_data, fs=1. / TR)\n",
    "    for i, e in enumerate(elements):\n",
    "\n",
    "        # Extract timeserie values\n",
    "        data = comp_data[i].T\n",
    "\n",
    "        # Plot timeserie\n",
    "        ax = fig.add_subplot(grid[i, :-1])\n",
    "        ax.plot(data, color=colors[i])\n",
    "        ax.set_xlim((0, len(data)))\n",
    "        ax.set_ylabel(e)\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        # Plot power density spectrum of all components\n",
    "        ax = fig.add_subplot(grid[i, -1])\n",
    "        ax.plot(freq, power_spectrum[i], color=colors[i])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save everyting in output figure\n",
    "    fig_signal = abspath(basename(comp_signal).replace('.txt', '_signal.png'))\n",
    "    fig.savefig(fig_signal, bbox_inches='tight', frameon=True, dpi=300, transparent=False)\n",
    "\n",
    "    # Plot individual components on functional mean image\n",
    "    fig = plt.figure(figsize=(16, 2 * n_components))\n",
    "    for i, cur_img in enumerate(iter_img(img_comp)):\n",
    "        ax = fig.add_subplot(n_components, 1, i + 1)\n",
    "        cuts = find_cut_slices(cur_img, direction='z', n_cuts=12)[1:-1]\n",
    "        plot_stat_map(cur_img, title='%s' % elements[i], colorbar=False,\n",
    "                      threshold=np.abs(cur_img.get_data()).max() * 0.1,\n",
    "                      bg_img=mean_file, display_mode='z', dim=0,\n",
    "                      cut_coords=cuts, annotate=False, axes=ax)\n",
    "\n",
    "    fig_brain = abspath(basename(comp_signal).replace('.txt', '_brain.png'))\n",
    "    fig.savefig(fig_brain, bbox_inches='tight', facecolor='black', transparent=False)\n",
    "    \n",
    "    # Reset seaborn\n",
    "    sns.reset_orig()\n",
    "    \n",
    "    return fig_signal, fig_brain\n",
    "\n",
    "ica_plot = Node(Function(input_names=['comp_signal', 'comp_file', 'mean_file',\n",
    "                                      'sub_id', 'ses_id', 'task_id', 'run_id', 'TR'],\n",
    "                         output_names=['fig_signal', 'fig_brain'],\n",
    "                         function=plot_ica_components),\n",
    "                name='ica_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update report\n",
    "def write_report(sub_id, ses_id, task_list, run_list, tFilter):\n",
    "\n",
    "    # Load template for functional preprocessing output\n",
    "    with open('/reports/report_template_preproc_func.html', 'r') as report:\n",
    "        func_temp = report.read()\n",
    "\n",
    "    # Create html filename for report\n",
    "    html_file = '/data/derivatives/fmriflows/sub-%s.html' % sub_id\n",
    "    if ses_id:\n",
    "        html_file = html_file.replace('.html', '_ses-%s.html' % ses_id)\n",
    "\n",
    "    # Old template placeholder\n",
    "    func_key = '<p>The functional preprocessing pipeline hasn\\'t been run yet.</p>'\n",
    "    \n",
    "    # Add new content to report\n",
    "    with open(html_file, 'r') as report:\n",
    "        txt = report.read()\n",
    "        \n",
    "        # Reset report with functional preprocessing template\n",
    "        cut_start = txt.find('Functional Preprocessing</a></h2>') + 33\n",
    "        cut_stop = txt.find('<!-- Section: 1st-Level Univariate Results-->')\n",
    "        txt = txt[:cut_start] + func_key + txt[cut_stop:]\n",
    "\n",
    "        txt_amendment = ''\n",
    "\n",
    "        # Go through the placeholder variables and replace them with values\n",
    "        for task_id in task_list:\n",
    "            \n",
    "            for t_filt in tFilter:\n",
    "            \n",
    "                if run_list:\n",
    "                    for run_id in run_list:\n",
    "\n",
    "                        func_txt = func_temp.replace('sub-placeholder', 'sub-%s' % sub_id)\n",
    "                        func_txt = func_txt.replace('task-placeholder', 'task-%s' % task_id)\n",
    "                        func_txt = func_txt.replace('run-placeholder', 'run-%02d' % run_id)\n",
    "                        func_txt = func_txt.replace(\n",
    "                            'tFilter_placeholder', 'tFilter_%s.%s' % (\n",
    "                                str(t_filt[0]), str(t_filt[1])))\n",
    "                        \n",
    "                        if ses_id:\n",
    "                            func_txt = func_txt.replace(\n",
    "                                'ses-placeholder', 'ses-%s' % ses_id)\n",
    "                        else:\n",
    "                            func_txt = func_txt.replace('ses-placeholder', '')\n",
    "                            func_txt = func_txt.replace('__', '_')\n",
    "\n",
    "                        txt_amendment += func_txt\n",
    "\n",
    "                else:\n",
    "\n",
    "                    func_txt = func_temp.replace('sub-placeholder', 'sub-%s' % sub_id)\n",
    "                    func_txt = func_txt.replace('task-placeholder', 'task-%s' % task_id)\n",
    "                    func_txt = func_txt.replace('run-placeholder', '')\n",
    "                    func_txt = func_txt.replace(\n",
    "                            'tFilter_placeholder', 'tFilter_%s.%s' % (\n",
    "                                str(t_filt[0]), str(t_filt[1])))\n",
    "\n",
    "                    func_txt = func_txt.replace('__', '_')\n",
    "\n",
    "                    if ses_id:\n",
    "                        func_txt = func_txt.replace(\n",
    "                            'ses-placeholder', 'ses-%s' % ses_id)\n",
    "                    else:\n",
    "                        func_txt = func_txt.replace('ses-placeholder', '')\n",
    "                        func_txt = func_txt.replace('__', '_')\n",
    "\n",
    "                    txt_amendment += func_txt\n",
    " \n",
    "    # Add pipeline graphs\n",
    "    txt_amendment += '<h3 class=\"h3\" style=\"position:left;font-weight:bold\">Graph of'\n",
    "    txt_amendment += ' Functional Preprocessing pipeline</h3>\\n    <object data=\"preproc_func/graph.png\"'\n",
    "    txt_amendment += ' type=\"image/png+xml\" style=\"width:100%\"></object>\\n  '\n",
    "    txt_amendment += ' <object data=\"preproc_func/graph_detailed.png\" type=\"image/png+xml\"'\n",
    "    txt_amendment += ' style=\"width:100%\"></object>\\n'\n",
    "\n",
    "    # Insert functional preprocessing report\n",
    "    txt = txt.replace(func_key, txt_amendment)\n",
    "\n",
    "    # Overwrite previous report\n",
    "    with open(html_file, 'w') as report:\n",
    "        report.writelines(txt)\n",
    "\n",
    "create_report = Node(Function(input_names=['sub_id', 'ses_id', 'task_list',\n",
    "                                           'run_list', 'tFilter'],\n",
    "                              output_names=['out_file'],\n",
    "                              function=write_report),\n",
    "                     name='create_report')\n",
    "create_report.inputs.run_list = run_list\n",
    "create_report.inputs.task_list = task_list\n",
    "create_report.inputs.tFilter = filters_temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create report Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create report workflow\n",
    "reportflow = Workflow(name='reportflow')\n",
    "\n",
    "# Add nodes to workflow and connect them\n",
    "reportflow.add_nodes([compcor_plot,\n",
    "                      confound_inspection,\n",
    "                      create_report,\n",
    "                      carpet_plot,\n",
    "                      ica_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Input & Output Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over subject, session, task and run id\n",
    "info_source = Node(IdentityInterface(fields=['subject_id',\n",
    "                                             'session_id',\n",
    "                                             'task_id',\n",
    "                                             'run_id']),\n",
    "                   name='info_source')\n",
    "\n",
    "iter_list = [('subject_id', subject_list),\n",
    "             ('task_id', task_list)]\n",
    "\n",
    "if session_list:\n",
    "    iter_list.append(('session_id', session_list))\n",
    "else:\n",
    "    info_source.inputs.session_id = ''\n",
    "\n",
    "if run_list:\n",
    "    iter_list.append(('run_id', run_list))\n",
    "else:\n",
    "    info_source.inputs.run_id = ''\n",
    "\n",
    "info_source.iterables = iter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path to input files\n",
    "def create_file_path(subject_id, session_id, task_id, run_id):\n",
    "\n",
    "    from bids.layout import BIDSLayout\n",
    "    layout = BIDSLayout('/data/')\n",
    "\n",
    "    # Find the right functional image\n",
    "    search_parameters = {'subject': subject_id,\n",
    "                         'return_type': 'file',\n",
    "                         'suffix': 'bold',\n",
    "                         'task': task_id,\n",
    "                         'extensions': 'nii.gz',\n",
    "                        }\n",
    "    if session_id:\n",
    "        search_parameters['session'] = session_id\n",
    "    if run_id:\n",
    "        search_parameters['run'] = run_id\n",
    "\n",
    "    func = layout.get(**search_parameters)[0]\n",
    "\n",
    "    # Collect structural images\n",
    "    template_path = '/data/derivatives/fmriflows/preproc_anat/sub-{0}/sub-{0}_'\n",
    "    if session_id:\n",
    "        template_path += 'ses-%s_' % session_id\n",
    "    template_anat = template_path + '{1}.nii.gz'\n",
    "    \n",
    "    # Collect normalization matrix\n",
    "    trans_path = template_path + '{1}.h5'\n",
    "    transforms = trans_path.format(subject_id, 'transformComposite')\n",
    "    \n",
    "    brain = template_anat.format(subject_id, 'brain')\n",
    "    brainmask = template_anat.format(subject_id, 'brainmask')\n",
    "    gm = template_anat.format(subject_id, 'seg_gm')\n",
    "    wm = template_anat.format(subject_id, 'seg_wm')\n",
    "    csf = template_anat.format(subject_id, 'seg_csf')\n",
    "    \n",
    "    return func, brain, brainmask, gm, wm, csf, transforms\n",
    "\n",
    "select_files = Node(Function(input_names=['subject_id', 'session_id', 'task_id', 'run_id'],\n",
    "                             output_names=['func', 'brain', 'brainmask', 'gm', 'wm', 'csf',\n",
    "                                           'transforms'],\n",
    "                             function=create_file_path),\n",
    "                    name='select_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Brain Mask and Extract Brain\n",
    "def crop_images(brain, brainmask, gm, wm, csf):\n",
    "\n",
    "    # Cropping image size to reduce memory load during coregistration\n",
    "    from nilearn.image import crop_img, resample_img\n",
    "    from os.path import basename, abspath\n",
    "    \n",
    "    brain_crop = crop_img(brain)\n",
    "    affine = brain_crop.affine\n",
    "    bshape = brain_crop.shape\n",
    "    brainmask_crop = resample_img(brainmask, target_affine=affine, target_shape=bshape)\n",
    "    gm_crop = resample_img(gm, target_affine=affine, target_shape=bshape)\n",
    "    wm_crop = resample_img(wm, target_affine=affine, target_shape=bshape)\n",
    "    csf_crop = resample_img(csf, target_affine=affine, target_shape=bshape)\n",
    "    \n",
    "    # Specify output name and save file\n",
    "    brain_out = abspath(basename(brain))\n",
    "    brainmask_out = abspath(basename(brainmask))\n",
    "    gm_out = abspath(basename(gm))\n",
    "    wm_out = abspath(basename(wm))\n",
    "    csf_out = abspath(basename(csf))\n",
    "    \n",
    "    brain_crop.to_filename(brain_out)\n",
    "    brainmask_crop.to_filename(brainmask_out)\n",
    "    gm_crop.to_filename(gm_out)\n",
    "    wm_crop.to_filename(wm_out)\n",
    "    csf_crop.to_filename(csf_out)\n",
    "\n",
    "    return brain_out, brainmask_out, gm_out, wm_out, csf_out\n",
    "\n",
    "crop_brain = Node(Function(input_names=['brain', 'brainmask', 'gm', 'wm', 'csf'],\n",
    "                           output_names=['brain', 'brainmask', 'gm', 'wm', 'csf'],\n",
    "                           function=crop_images),\n",
    "                  name='crop_brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Brain Mask and Extract Brain\n",
    "def create_templates(template_dir, res_norm):\n",
    "\n",
    "    # Resample template brain to desired resolution\n",
    "    from nibabel import load, Nifti1Image\n",
    "    from nibabel.spaces import vox2out_vox\n",
    "    from nilearn.image import resample_img\n",
    "    from os.path import basename, abspath\n",
    "    \n",
    "    # Resample template images into requested resolution\n",
    "    out_files = []\n",
    "    for t in ['brain', 'mask', 'tpm_gm', 'tpm_wm', 'tpm_csf']:\n",
    "        template = template_dir + '/1.0mm_%s.nii.gz' % t\n",
    "        img = load(template)\n",
    "        target_shape, target_affine = vox2out_vox(img, voxel_sizes=res_norm)\n",
    "        img_resample = resample_img(img, target_affine, target_shape, clip=True)\n",
    "        norm_template = abspath('template_{}_{}.nii.gz'.format(\n",
    "            t, '_'.join([str(n) for n in res_norm])))\n",
    "        img_resample.to_filename(norm_template)\n",
    "        out_files.append(norm_template)\n",
    "\n",
    "    return out_files\n",
    "\n",
    "template_repository = Node(Function(input_names=['template_dir', 'res_norm'],\n",
    "                                     output_names=['brain', 'mask',\n",
    "                                                   'tpm_gm', 'tpm_wm', 'tpm_csf'],\n",
    "                                     function=create_templates),\n",
    "                  name='template_repository')\n",
    "\n",
    "template_repository.inputs.template_dir = '/templates/mni_icbm152_nlin_asym_09c'\n",
    "template_repository.inputs.res_norm = res_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sequence specifications of functional images\n",
    "def get_parameters(func, ref_slice):\n",
    "    \n",
    "    from bids.layout import BIDSLayout\n",
    "    layout = BIDSLayout(\"/data/\")\n",
    "    parameter_info = layout.get_metadata(func)\n",
    "    \n",
    "    # Read out relevant parameters\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    n_slices = nb.load(func).shape[2]\n",
    "    TR = parameter_info['RepetitionTime']\n",
    "    \n",
    "    # If slice time onset are available, use them\n",
    "    if 'SliceTiming' in parameter_info.keys():\n",
    "        slice_order = parameter_info['SliceTiming']\n",
    "        if np.mean(slice_order) <= 20:\n",
    "            slice_order=[s*1000 for s in slice_order]\n",
    "    else:\n",
    "        # If not available, set time onset of all slices to zero\n",
    "        slice_order = [0] * n_slices\n",
    "    nslices = len(slice_order)\n",
    "    time_acquisition = float(TR)-(TR/nslices)\n",
    "    \n",
    "    return TR, slice_order, nslices, time_acquisition\n",
    "\n",
    "get_param = Node(Function(input_names=['func', 'ref_slice'],\n",
    "                          output_names=['TR', 'slice_order',\n",
    "                                        'nslices', 'time_acquisition'],\n",
    "                          function=get_parameters),\n",
    "                 name='get_param')\n",
    "get_param.inputs.ref_slice = ref_timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the different temporal filters\n",
    "def get_temporal_filters(tFilter):\n",
    "    \n",
    "    # Extract high-pass value for CompCor\n",
    "    high_pass = tFilter[1] if tFilter[1] != None else 100.\n",
    "    \n",
    "    return tFilter, high_pass\n",
    "\n",
    "get_tfilters = Node(Function(input_names=['tFilter'],\n",
    "                          output_names=['tFilter', 'high_pass'],\n",
    "                          function=get_temporal_filters),\n",
    "                 name='get_tfilters')\n",
    "get_tfilters.iterables = ('tFilter', filters_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant outputs in a datasink\n",
    "datasink = Node(DataSink(base_directory=exp_dir,\n",
    "                         container=out_dir),\n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following naming substitutions for the datasink\n",
    "substitutions = [('/asub-', '/sub-'),\n",
    "                 ('_bold', ''),\n",
    "                 ('_ras', ''),\n",
    "                 ('_tf', ''),\n",
    "                 ('_mcf', ''),\n",
    "                 ('_stc', ''),\n",
    "                 ('_warped', ''),\n",
    "                 ('.nii.gz_', '_'),\n",
    "                 ('_mean_', '_'),\n",
    "                 ('mask_000', 'maskT'),\n",
    "                 ('.nii.gz.par', '.par'),\n",
    "                ]\n",
    "\n",
    "substitutions += [('tFilter_%s.%s/' % (t[0], t[1]),\n",
    "                   'tFilter_%s.%s_' % (t[0], t[1]))\n",
    "                  for t in filters_temporal]\n",
    "\n",
    "substitutions += [('_sFilter_%s.%s/' % (s[0], s[1]), '')\n",
    "                  for s in filters_spatial]\n",
    "\n",
    "substitutions += [('%s_%smm' % (s[0], s[1]),\n",
    "                   'sFilter_%s_%smm' % (s[0], s[1]))\n",
    "                  for s in filters_spatial]                \n",
    "\n",
    "for sub in subject_list:\n",
    "    substitutions += [('sub-%s' % sub, '_')]\n",
    "\n",
    "for sess in session_list:\n",
    "    substitutions += [('ses-%s' % sess, '_')]\n",
    "\n",
    "for task in task_list:\n",
    "    substitutions += [('task-%s' % task, '_')]\n",
    "\n",
    "for run in run_list:\n",
    "    substitutions += [('run-%02d' % run, '_')]\n",
    "    \n",
    "for sub in subject_list:\n",
    "    for task in task_list:\n",
    "\n",
    "        substitutions += [('_subject_id_%s_task_id_%s/' % (sub, task),\n",
    "                           'sub-{0}/sub-{0}_task-{1}_'.format(sub, task))]\n",
    "        for sess in session_list:\n",
    "            substitutions += [('_session_id_{0}sub-{1}/sub-{1}_task-{2}_'.format(sess, sub, task),\n",
    "                               'sub-{0}/sub-{0}_ses-{1}_task-{2}_'.format(sub, sess, task))]\n",
    "            for run in run_list:\n",
    "                substitutions += [('_run_id_{0:d}sub-{1}/sub-{1}_ses-{2}_task-{3}_'.format(run, sub, sess, task),\n",
    "                                   'sub-{0}/sub-{0}_ses-{1}_task-{2}_run-{3:02d}_'.format(sub, sess, task, run))]\n",
    "\n",
    "        for run in run_list:\n",
    "            substitutions += [('_run_id_{0:d}sub-{1}/sub-{1}_task-{2}_'.format(run, sub, task),\n",
    "                               'sub-{0}/sub-{0}_task-{1}_run-{2:02d}_'.format(sub, task, run))]\n",
    "            \n",
    "substitutions += [('__', '_')] * 100\n",
    "substitutions += [('_.', '.')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create Functional Preprocessing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functional preprocessing workflow\n",
    "preproc_func = Workflow(name='preproc_func')\n",
    "preproc_func.base_dir = work_dir\n",
    "\n",
    "# Connect input nodes to each other\n",
    "preproc_func.connect([(info_source, select_files, [('subject_id', 'subject_id'),\n",
    "                                                   ('session_id', 'session_id'),\n",
    "                                                   ('task_id', 'task_id'),\n",
    "                                                   ('run_id', 'run_id')]),\n",
    "                      (select_files, crop_brain, [('brain', 'brain'),\n",
    "                                                  ('brainmask', 'brainmask'),\n",
    "                                                  ('gm', 'gm'),\n",
    "                                                  ('wm', 'wm'),\n",
    "                                                  ('csf', 'csf'),\n",
    "                                                 ]),\n",
    "                      (select_files, get_param, [('func', 'func')]),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input and output nodes and connect them to the main workflow\n",
    "preproc_func.connect([(crop_brain, mainflow, [('brain', 'coregflow.coreg_pre.reference'),\n",
    "                                              ('brain', 'coregflow.coreg_bbr.reference'),\n",
    "                                              ('wm', 'coregflow.coreg_bbr.wm_seg'),\n",
    "                                             ]),\n",
    "                      (get_param, mainflow, [('TR', 'slice_time.TR'),\n",
    "                                             ('TR', 'filterflow.temporal_filter.tr'),\n",
    "                                             ('TR', 'motion_parameters.TR'),\n",
    "                                             ('TR', 'apply_warp.TR'),\n",
    "                                             ('slice_order', 'slice_time.slice_order'),\n",
    "                                             ('nslices', 'slice_time.nslices'),\n",
    "                                             ('time_acquisition', 'slice_time.time_acquisition'),\n",
    "                                            ]),\n",
    "                      (get_tfilters, mainflow, [('tFilter', 'motion_parameters.tFilter'),\n",
    "                                                ('tFilter', 'filterflow.temporal_filter.tFilter'),\n",
    "                                               ]),\n",
    "                      (select_files, mainflow, [('func', 'prepareflow.reorient.in_file'),\n",
    "                                                ('transforms', 'apply_warp.transforms')]),\n",
    "                      (template_repository, mainflow, [('brain', 'apply_warp.template')]),\n",
    "                      (crop_brain, mainflow, [('brain', 'apply_warp.brain')]),\n",
    "                      (mainflow, datasink, [\n",
    "                          ('prepareflow.nss_detection.nss_file', 'preproc_func.@nss'),\n",
    "                          ('estimate_motion.par_file', 'preproc_func.@par'),\n",
    "                          ('motion_parameters.par_file', 'preproc_func.@par_filtered'),\n",
    "                          ('filterflow.masks_for_warp.mask_func', 'preproc_func.@mask_func'),\n",
    "                          ('filterflow.masks_for_warp.mask_conf', 'preproc_func.@mask_conf'),\n",
    "                          ('filterflow.temporal_filter.mean_file', 'preproc_func.@mean'),\n",
    "                          ('filterflow.spatial_filter.out_file', 'preproc_func.@func')]),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input and output nodes and connect them to the confound workflow\n",
    "preproc_func.connect([(crop_brain, confflow, [('brainmask', 'average_signal.brainmask'),\n",
    "                                              ('gm', 'average_signal.gm'),\n",
    "                                              ('wm', 'average_signal.wm'),\n",
    "                                              ('csf', 'average_signal.csf'),\n",
    "                                              ('wm', 'acomp_masks.wm'),\n",
    "                                              ('csf', 'acomp_masks.csf')]),\n",
    "                      (template_repository, confflow, [('mask', 'average_signal.temp_mask'),\n",
    "                                                       ('tpm_gm', 'average_signal.temp_gm'),\n",
    "                                                       ('tpm_wm', 'average_signal.temp_wm'),\n",
    "                                                       ('tpm_csf', 'average_signal.temp_csf'),\n",
    "                                                       ('tpm_wm', 'acomp_masks.temp_wm'),\n",
    "                                                       ('tpm_csf', 'acomp_masks.temp_csf')]),\n",
    "                      (get_param, confflow, [('TR', 'aCompCor.repetition_time'),\n",
    "                                             ('TR', 'tCompCor.repetition_time'),\n",
    "                                             ('TR', 'FD.series_tr'),\n",
    "                                             ('TR', 'dvars.series_tr'),\n",
    "                                            ]),\n",
    "                      (get_tfilters, confflow, [('high_pass', 'aCompCor.high_pass_cutoff'),\n",
    "                                                ('high_pass', 'tCompCor.high_pass_cutoff'),\n",
    "                                               ]),\n",
    "                      (confflow, datasink, [\n",
    "                          ('tCompCor.high_variance_masks', 'preproc_func.@maskT'),\n",
    "                          ('acomp_masks.out_file', 'preproc_func.@maskA'),\n",
    "                          ('combine_confounds.out_file', 'preproc_func.@confound_tsv')\n",
    "                      ]),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect main workflow with confound workflow\n",
    "preproc_func.connect([(mainflow, confflow, [\n",
    "                          ('filterflow.temporal_filter.mean_file', 'acomp_masks.mean_file'),\n",
    "                          ('filterflow.masks_for_warp.mask_conf', 'dvars.in_mask'),\n",
    "                          ('filterflow.masks_for_warp.mask_conf', 'acomp_masks.brainmask'),\n",
    "                          ('filterflow.masks_for_warp.mask_conf', 'tCompCor.mask_files'),\n",
    "                          ('filterflow.masks_for_warp.mask_conf', 'average_signal.template_file'),\n",
    "                          ('filterflow.masks_for_warp.mask_conf', 'compute_ica.mask_file'),\n",
    "                          ('filterflow.temporal_filter.out_file', 'compute_ica.in_file'),\n",
    "                          ('filterflow.temporal_filter.out_file', 'aCompCor.realigned_file'),\n",
    "                          ('filterflow.temporal_filter.out_file', 'tCompCor.realigned_file'),\n",
    "                          ('filterflow.temporal_filter.out_file', 'average_signal.in_file'),\n",
    "                          ('filterflow.temporal_filter.out_file', 'dvars.in_file'),\n",
    "                          ('motion_parameters.par_file', 'combine_confounds.par_mc'),\n",
    "                          ('estimate_motion.par_file', 'combine_confounds.par_mc_raw'),\n",
    "                          ('motion_parameters.par_file', 'friston24.in_file'),\n",
    "                          ('motion_parameters.par_file', 'FD.in_file'),\n",
    "                          ])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input and output nodes and connect them to the report workflow\n",
    "preproc_func.connect([(info_source, reportflow, [('subject_id', 'compcor_plot.sub_id'),\n",
    "                                                 ('session_id', 'compcor_plot.ses_id'),\n",
    "                                                 ('task_id', 'compcor_plot.task_id'),\n",
    "                                                 ('run_id', 'compcor_plot.run_id'),\n",
    "\n",
    "                                                 ('subject_id', 'create_report.sub_id'),\n",
    "                                                 ('session_id', 'create_report.ses_id'),\n",
    "\n",
    "                                                 ('subject_id', 'carpet_plot.sub_id'),\n",
    "                                                 ('session_id', 'carpet_plot.ses_id'),\n",
    "                                                 ('task_id', 'carpet_plot.task_id'),\n",
    "                                                 ('run_id', 'carpet_plot.run_id'),\n",
    "                                                ]),\n",
    "                      (crop_brain, reportflow, [('gm', 'carpet_plot.seg_gm'),\n",
    "                                                ('wm', 'carpet_plot.seg_wm'),\n",
    "                                                ('csf', 'carpet_plot.seg_csf'),\n",
    "                                               ]),\n",
    "                      (get_param, reportflow, [('TR', 'ica_plot.TR')]),\n",
    "                      (mainflow, reportflow, [('filterflow.masks_for_warp.mask_conf',\n",
    "                                               'carpet_plot.brainmask')]),\n",
    "                      (reportflow, datasink, [\n",
    "                          ('compcor_plot.out_file', 'preproc_func.@compcor_plot'),\n",
    "                          ('carpet_plot.out_file', 'preproc_func.@carpet_plot'),\n",
    "                          ('confound_inspection.outlier_file', 'preproc_func.@conf_inspect'),\n",
    "                          ('confound_inspection.plot_main', 'preproc_func.@conf_main'),\n",
    "                          ('confound_inspection.plot_motion', 'preproc_func.@conf_motion'),\n",
    "                          ('confound_inspection.plot_compA', 'preproc_func.@conf_compA'),\n",
    "                          ('confound_inspection.plot_compT', 'preproc_func.@conf_compT'),\n",
    "                          ('ica_plot.fig_signal', 'preproc_func.@fig_signal'),\n",
    "                          ('ica_plot.fig_brain', 'preproc_func.@fig_brain'),\n",
    "                      ]),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect main and confound workflow with report workflow\n",
    "preproc_func.connect([(mainflow, reportflow, [\n",
    "                          ('filterflow.temporal_filter.mean_file', 'compcor_plot.mean'),\n",
    "                          ('filterflow.temporal_filter.mean_file', 'ica_plot.mean_file'),\n",
    "                          ('filterflow.masks_for_warp.mask_conf', 'compcor_plot.brainmask'),\n",
    "                          ('filterflow.temporal_filter.out_file', 'carpet_plot.in_file'),\n",
    "                          ]),\n",
    "                      (confflow, reportflow, [\n",
    "                          ('tCompCor.high_variance_masks', 'compcor_plot.maskT'),\n",
    "                          ('acomp_masks.out_file', 'compcor_plot.maskA'),\n",
    "                          ('combine_confounds.out_file', 'confound_inspection.confounds'),\n",
    "                          ('compute_ica.comp_signal', 'ica_plot.comp_signal'),\n",
    "                          ('compute_ica.comp_file', 'ica_plot.comp_file'),\n",
    "                          ])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create preproc_func output graph\n",
    "preproc_func.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph in the notebook (NBVAL_SKIP)\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(preproc_func.base_dir, 'preproc_func', 'graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the workflow in parallel mode\n",
    "res = preproc_func.run(plugin='MultiProc', plugin_args={'n_procs' : n_proc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save workflow graph visualizations in datasink\n",
    "preproc_func.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "preproc_func.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "from shutil import copyfile\n",
    "copyfile(opj(preproc_func.base_dir, 'preproc_func', 'graph.png'),\n",
    "         opj(exp_dir, out_dir, 'preproc_func', 'graph.png'))\n",
    "copyfile(opj(preproc_func.base_dir, 'preproc_func', 'graph_detailed.png'),\n",
    "         opj(exp_dir, out_dir, 'preproc_func', 'graph_detailed.png'));"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
